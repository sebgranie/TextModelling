{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "9b62aa3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/sebastien/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/sebastien/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Text Preprocessing\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "stop_words = stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "from operator import add\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "import random\n",
    "from random import sample\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "afb4032d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_rows', 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "6afea1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_df = pd.read_csv('/home/sebastien/Documents/Glasgow/Semester2/Text_As_Data/coursework/archive/Reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "26b8be8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "568454"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(whole_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "a469e0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Shortening the dataset to 10,000 reviews. \n",
    "whole_df = pd.read_csv('/home/sebastien/Documents/Glasgow/Semester2/Text_As_Data/coursework/archive/Reviews.csv')\n",
    "df = whole_df[:10000]\n",
    "\n",
    "#shuffled_reviews = random.sample(df, k=len(df))\n",
    "\n",
    "## Split the data into 60% train, 20% validation, 20% testing.\n",
    "\n",
    "#train_frac = 0.6\n",
    "#split_idx = int(train_frac * len(shuffled_reviews))\n",
    "#train_reviews = shuffled_reviews[:split_idx]\n",
    "#validation_test_reviews = shuffled_reviews[split_idx:]\n",
    "\n",
    "#valid_test_frac = 0.5\n",
    "#split_id = int(valid_test_frac * len(validation_test_reviews))\n",
    "#validation_reviews = validation_test_reviews[:split_id]\n",
    "#test_reviews = validation_test_reviews[split_id:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "52bceba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                         int64\n",
       "ProductId                 object\n",
       "UserId                    object\n",
       "ProfileName               object\n",
       "HelpfulnessNumerator       int64\n",
       "HelpfulnessDenominator     int64\n",
       "Score                      int64\n",
       "Time                       int64\n",
       "Summary                   object\n",
       "Text                      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "52c36c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "7b2c59d9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "eacd6baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = whole_df[20000:45000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "bebcd0db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 10)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "56bcb8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "f5711e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.drop(['ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator', 'HelpfulnessDenominator', 'Time', 'Summary'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "a10ff025",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.loc[df_test['Score'] == 1, 'Sentiment'] = 'Negative'\n",
    "df_test.loc[df_test['Score'] == 2, 'Sentiment'] = 'Negative'\n",
    "df_test.loc[df_test['Score'] == 3, 'Sentiment'] = 'Neutral'\n",
    "df_test.loc[df_test['Score'] == 4, 'Sentiment'] = 'Positive'\n",
    "df_test.loc[df_test['Score'] == 5, 'Sentiment'] = 'Positive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "0f7a9273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3788\n"
     ]
    }
   ],
   "source": [
    "df_negative = len(df_test[df_test[\"Sentiment\"]==\"Negative\"])\n",
    "print(df_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "56cd818f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1946\n"
     ]
    }
   ],
   "source": [
    "df_neutral = len(df_test[df_test[\"Sentiment\"]==\"Neutral\"])\n",
    "print(df_neutral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "7f212f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19266\n"
     ]
    }
   ],
   "source": [
    "df_positive = len(df_test[df_test[\"Sentiment\"]==\"Positive\"])\n",
    "print(df_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "f560d762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class 0: (19266, 4)\n",
      "class 1: (1946, 4)\n",
      "class 2: (3788, 4)\n"
     ]
    }
   ],
   "source": [
    "# class count\n",
    "class_count_0, class_count_1, class_count_2 = df_test['Sentiment'].value_counts()\n",
    "\n",
    "# Separate class\n",
    "class_0 = df_test[df_test['Sentiment'] == 'Positive']\n",
    "class_1 = df_test[df_test['Sentiment'] == 'Neutral']\n",
    "class_2 = df_test[df_test['Sentiment'] == 'Negative']\n",
    "# print the shape of the class\n",
    "print('class 0:', class_0.shape)\n",
    "print('class 1:', class_1.shape)\n",
    "print('class 2:', class_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3380dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class_0_under = random.sample(class_0, class_count_2)\n",
    "#rows = random.sample(data, int(len(data)*sample_split))\n",
    "#test_under = pd.concat([class_0_under, class_2], axis=0)\n",
    "\n",
    "#print(\"total class of 0 and 2:\",test_under['Sentiment'].value_counts())\n",
    "# plot the count after under-sampeling\n",
    "#test_under['Sentiment'].value_counts().plot(kind='bar', title='count (target)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d17a8364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15000"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = class_count_0 - (10000 - class_count_1 - class_count_2)\n",
    "size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "1c9d66c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_0_short = class_0.drop(class_0.index[range(size)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "d233112c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4266, 4)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_0_short.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "1ccc4aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class 0: (4266, 4)\n",
      "class 1: (1946, 4)\n",
      "class 2: (3788, 4)\n"
     ]
    }
   ],
   "source": [
    "print('class 0:', class_0_short.shape)\n",
    "print('class 1:', class_1.shape)\n",
    "print('class 2:', class_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "ec880317",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [class_0_short, class_1, class_2]\n",
    "result = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "02f93a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = result.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "3800c1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 4)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "e9c1c9a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Score</th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39570</th>\n",
       "      <td>39571</td>\n",
       "      <td>5</td>\n",
       "      <td>IN THE PAST I HAVE HAD TROUBLE WITH OTHER COMP...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39573</th>\n",
       "      <td>39574</td>\n",
       "      <td>4</td>\n",
       "      <td>I must admit my purchase was made out of curio...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39574</th>\n",
       "      <td>39575</td>\n",
       "      <td>5</td>\n",
       "      <td>I discovered Ambrosia custard while in Ireland...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39575</th>\n",
       "      <td>39576</td>\n",
       "      <td>5</td>\n",
       "      <td>A friend from England ordered this custard for...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39576</th>\n",
       "      <td>39577</td>\n",
       "      <td>4</td>\n",
       "      <td>This is a very rich version of British \"custar...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id  Score                                               Text  \\\n",
       "39570  39571      5  IN THE PAST I HAVE HAD TROUBLE WITH OTHER COMP...   \n",
       "39573  39574      4  I must admit my purchase was made out of curio...   \n",
       "39574  39575      5  I discovered Ambrosia custard while in Ireland...   \n",
       "39575  39576      5  A friend from England ordered this custard for...   \n",
       "39576  39577      4  This is a very rich version of British \"custar...   \n",
       "\n",
       "      Sentiment  \n",
       "39570  Positive  \n",
       "39573  Positive  \n",
       "39574  Positive  \n",
       "39575  Positive  \n",
       "39576  Positive  "
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "79a56ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_test[\"Text\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7683d013",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_test[\"Text\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "21a54f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_test[\"Text\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8c80ba36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_test[\"Text\"][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d6c72b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b031ce7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b91bca8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "    words = text.split()\n",
    "    words = [w for w in words if w not in stop_words]\n",
    "    words = [lemmatizer.lemmatize(w) for w in words]\n",
    "    #text = ' '.join(words)\n",
    "    return text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0b9d6608",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_vocabulary(corpus):\n",
    "    unique_tokens = sorted(set( t for token_list in corpus for t in token_list))\n",
    "    token_to_id = { v:i for i,v in enumerate(unique_tokens)}\n",
    "    return token_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fa119ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_frequency(corpus):\n",
    "    return Counter(token for sublist in corpus for token in set(sublist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f3542f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_pipeline_spacy(text):\n",
    "    tokens = []\n",
    "    doc = nlp(text)\n",
    "    for t in doc:\n",
    "        if not t.is_stop and not t.is_punct and not t.is_space:\n",
    "            tokens.append(t.lemma_.lower())\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "848a3d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tf_sparse(tokens, vocab):\n",
    "    vect = Counter(tokens)\n",
    "    sparse = { vocab[t]:c for t,c in vect.items()}\n",
    "    return sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2df37328",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tfidf_sparse(tokens, vocab, doc_freq, N):\n",
    "    sparse_vector = {}\n",
    "    counts = Counter(tokens)\n",
    "    for t,c in counts.items():\n",
    "        tf = 1 + math.log10(c) if c > 0 else 0\n",
    "        idf = math.log10( N / doc_freq[t] )\n",
    "        sparse_vector[vocab[t]] = tf*idf\n",
    "    return sparse_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fc803a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_euclidean_distance(sv1, sv2):\n",
    "    d2 = 0\n",
    "    indices = set(sv1).union(sv2)\n",
    "    for i in indices:\n",
    "        diff = sv2.get(i,0) - sv1.get(i,0)\n",
    "        d2 += diff * diff\n",
    "    return math.sqrt(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "08b75387",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_sparse_vector(sv):\n",
    "    d = math.sqrt(sum(val*val for index,val in sv.items()))\n",
    "    norm_vect = { index:val/d for index,val in sv.items()}\n",
    "    return norm_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "971fbd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def union_vectors(sparse_vectors):\n",
    "    return set().union(*sparse_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "01091b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_to_dense(sv, vector_length):\n",
    "    dense_vector = []\n",
    "    for index in range(vector_length):\n",
    "        dense_vector.append(sv.get(index,0))\n",
    "    return dense_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ca638ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_pipeline_spacy(text):\n",
    "    tokens = []\n",
    "    doc = nlp(text)\n",
    "    for t in doc:\n",
    "        if not t.is_stop and not t.is_punct and not t.is_space:\n",
    "            tokens.append(t.lemma_.lower())\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ac70fa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_test['Text'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53ad077",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ec2f72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2815f2ae",
   "metadata": {},
   "source": [
    "## Q2 - Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "a342646a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenized = [ text_pipeline_spacy(x) for x in df_test['Text'] ]\n",
    "#df_test['tokenized'] = df_test['Text'].apply(preprocess_text)\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "sparse_tf_idf = vectorizer.fit_transform(df_test['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "7f36e254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 20007)\n"
     ]
    }
   ],
   "source": [
    "print(sparse_tf_idf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "bfdad197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "\n",
    "rand = np.random.choice(sparse_tf_idf.shape[0], k, replace=False)\n",
    "centroids = np.array(sparse_tf_idf[rand].todense())\n",
    "\n",
    "clusters = np.zeros(sparse_tf_idf.shape[0])\n",
    "old_clusters = np.zeros(sparse_tf_idf.shape[0])\n",
    "\n",
    "print(centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "93cf19b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(centroids.mean(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "91d300a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "692\n",
      "1954\n",
      "4990\n",
      "1849\n",
      "515\n",
      "\n",
      "\n",
      "sum :  10000\n",
      "[4.04943124 7.35442998 9.68342671 7.46122069 5.44239492]\n",
      "[5.42204657 6.31985738 6.58771755 5.73345072 5.95963295]\n",
      "\n",
      "\n",
      "834\n",
      "1249\n",
      "4677\n",
      "2455\n",
      "785\n",
      "\n",
      "\n",
      "sum :  10000\n",
      "[5.42204657 6.31985738 6.58771755 5.73345072 5.95963295]\n",
      "[6.04810188 6.83617548 6.49307421 5.54076584 6.48527526]\n",
      "\n",
      "\n",
      "811\n",
      "1084\n",
      "4683\n",
      "2525\n",
      "897\n",
      "\n",
      "\n",
      "sum :  10000\n",
      "[6.04810188 6.83617548 6.49307421 5.54076584 6.48527526]\n",
      "[6.11789713 7.36748794 6.28031011 5.57390857 6.92457806]\n",
      "\n",
      "\n",
      "792\n",
      "1064\n",
      "4657\n",
      "2475\n",
      "1012\n",
      "\n",
      "\n",
      "sum :  10000\n",
      "[6.11789713 7.36748794 6.28031011 5.57390857 6.92457806]\n",
      "[6.13660732 7.58315126 6.13359958 5.65031167 7.08178744]\n",
      "\n",
      "\n",
      "785\n",
      "1101\n",
      "4675\n",
      "2375\n",
      "1064\n",
      "\n",
      "\n",
      "sum :  10000\n",
      "[6.13660732 7.58315126 6.13359958 5.65031167 7.08178744]\n",
      "[6.14785453 7.71213578 6.01472834 5.72611346 7.15096588]\n",
      "\n",
      "\n",
      "772\n",
      "1165\n",
      "4693\n",
      "2291\n",
      "1079\n",
      "\n",
      "\n",
      "sum :  10000\n",
      "[6.14785453 7.71213578 6.01472834 5.72611346 7.15096588]\n",
      "[6.1573827  7.82400204 5.91287689 5.80913326 7.15274523]\n",
      "\n",
      "\n",
      "763\n",
      "1242\n",
      "4720\n",
      "2207\n",
      "1068\n",
      "\n",
      "\n",
      "sum :  10000\n",
      "[6.1573827  7.82400204 5.91287689 5.80913326 7.15274523]\n",
      "[6.1520876  7.86593    5.8437776  5.86660326 7.16327516]\n",
      "\n",
      "\n",
      "759\n",
      "1303\n",
      "4727\n",
      "2148\n",
      "1063\n",
      "\n",
      "\n",
      "sum :  10000\n",
      "[6.1520876  7.86593    5.8437776  5.86660326 7.16327516]\n",
      "[6.16098873 7.89804301 5.79708864 5.90587276 7.13841603]\n",
      "\n",
      "\n",
      "757\n",
      "1357\n",
      "4717\n",
      "2105\n",
      "1064\n",
      "\n",
      "\n",
      "sum :  10000\n",
      "[6.16098873 7.89804301 5.79708864 5.90587276 7.13841603]\n",
      "[6.15184214 7.93685425 5.76269992 5.91516537 7.12668714]\n",
      "\n",
      "\n",
      "755\n",
      "1386\n",
      "4726\n",
      "2073\n",
      "1060\n",
      "\n",
      "\n",
      "sum :  10000\n",
      "[6.15184214 7.93685425 5.76269992 5.91516537 7.12668714]\n",
      "[6.1567157  7.95736274 5.73953799 5.92446241 7.13248791]\n",
      "\n",
      "\n",
      "754\n",
      "1406\n",
      "4735\n",
      "2050\n",
      "1055\n",
      "\n",
      "\n",
      "sum :  10000\n",
      "[6.1567157  7.95736274 5.73953799 5.92446241 7.13248791]\n",
      "[6.15824301 7.98678597 5.71997654 5.9401814  7.11841928]\n",
      "\n",
      "\n",
      "752\n",
      "1432\n",
      "4731\n",
      "2031\n",
      "1054\n",
      "\n",
      "\n",
      "sum :  10000\n",
      "[6.15824301 7.98678597 5.71997654 5.9401814  7.11841928]\n",
      "[6.1542081  7.99329425 5.70623304 5.94947893 7.10643963]\n",
      "\n",
      "\n",
      "752\n",
      "1444\n",
      "4731\n",
      "2021\n",
      "1052\n",
      "\n",
      "\n",
      "sum :  10000\n",
      "[6.1542081  7.99329425 5.70623304 5.94947893 7.10643963]\n",
      "[6.1542081  7.99754158 5.69848342 5.95517245 7.10340904]\n",
      "\n",
      "\n",
      "752\n",
      "1449\n",
      "4732\n",
      "2015\n",
      "1052\n",
      "\n",
      "\n",
      "sum :  10000\n",
      "[6.1542081  7.99754158 5.69848342 5.95517245 7.10340904]\n",
      "[6.1542081  7.99735164 5.6945135  5.95969143 7.10340904]\n",
      "\n",
      "\n",
      "752\n",
      "1455\n",
      "4735\n",
      "2007\n",
      "1051\n",
      "\n",
      "\n",
      "sum :  10000\n",
      "[6.1542081  7.99735164 5.6945135  5.95969143 7.10340904]\n",
      "[6.1542081  7.99578695 5.69055327 5.96474586 7.10397743]\n",
      "\n",
      "\n",
      "752\n",
      "1456\n",
      "4742\n",
      "1999\n",
      "1051\n",
      "\n",
      "\n",
      "sum :  10000\n",
      "[6.1542081  7.99578695 5.69055327 5.96474586 7.10397743]\n",
      "[6.1542081  7.99582356 5.68840048 5.96977013 7.10397743]\n",
      "\n",
      "\n",
      "752\n",
      "1457\n",
      "4751\n",
      "1990\n",
      "1050\n",
      "\n",
      "\n",
      "sum :  10000\n",
      "[6.1542081  7.99582356 5.68840048 5.96977013 7.10397743]\n",
      "[6.1542081  7.99730696 5.6866986  5.9751058  7.10106966]\n",
      "\n",
      "\n",
      "752\n",
      "1459\n",
      "4755\n",
      "1985\n",
      "1049\n",
      "\n",
      "\n",
      "sum :  10000\n",
      "[6.1542081  7.99730696 5.6866986  5.9751058  7.10106966]\n",
      "[6.1542081  7.99694661 5.68634647 5.97638728 7.09905971]\n",
      "\n",
      "\n",
      "752\n",
      "1459\n",
      "4758\n",
      "1981\n",
      "1050\n",
      "\n",
      "\n",
      "sum :  10000\n",
      "[6.1542081  7.99694661 5.68634647 5.97638728 7.09905971]\n",
      "[6.1542081  7.99694661 5.68662638 5.97720977 7.09599902]\n",
      "\n",
      "\n",
      "752\n",
      "1458\n",
      "4760\n",
      "1979\n",
      "1051\n",
      "\n",
      "\n",
      "sum :  10000\n",
      "[6.1542081  7.99694661 5.68662638 5.97720977 7.09599902]\n",
      "[6.1542081  7.99908897 5.68679668 5.97682367 7.09439294]\n",
      "\n",
      "\n",
      "752\n",
      "1458\n",
      "4760\n",
      "1979\n",
      "1051\n",
      "\n",
      "\n",
      "sum :  10000\n",
      "old_clusters :\n",
      " [2. 2. 2. ... 1. 2. 4.]\n",
      "clusters :\n",
      " [2. 2. 2. ... 1. 2. 4.]\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "loop = 0\n",
    "while True:\n",
    "    for i, vector in enumerate(sparse_tf_idf):\n",
    "        # Compute the distance between each vector to all k centroids\n",
    "        distances = np.linalg.norm(vector.todense() - centroids, axis=1)\n",
    "        # Assign each vector to the closest centroid\n",
    "        clusters[i] = np.argmin(distances)\n",
    "\n",
    "    zeros = list(clusters).count(0)\n",
    "    ones = list(clusters).count(1)\n",
    "    twos = list(clusters).count(2)\n",
    "    threes = list(clusters).count(3)\n",
    "    fours = list(clusters).count(4)\n",
    "    print('\\n')\n",
    "    print(zeros)\n",
    "    print(ones)\n",
    "    print(twos)\n",
    "    print(threes)\n",
    "    print(fours)\n",
    "    print('\\n')\n",
    "    print('sum : ', zeros+ones+twos+threes+fours)\n",
    "    \n",
    "\n",
    "    # Check when equilibrium is found\n",
    "    if (old_clusters == clusters).all():\n",
    "        break\n",
    "\n",
    "    # Keep previous assignment of vectors to centroids in memory to compare\n",
    "    old_clusters = clusters.copy()\n",
    "    \n",
    "    # Update the value of centroids using their respectively assigned vectors\n",
    "    print(centroids.sum(axis=1))\n",
    "    for cluster in range(k):\n",
    "        index_cluster = clusters == cluster\n",
    "        cluster_data = sparse_tf_idf[index_cluster]\n",
    "        # Each centroid is the updated to be the mean of its assigned vectors\n",
    "        centroids[cluster] = np.array(cluster_data.mean(axis=0))\n",
    "    print(centroids.sum(axis=1))\n",
    "    loop += 1\n",
    "\n",
    "print(\"old_clusters :\\n\", old_clusters)\n",
    "print(\"clusters :\\n\", clusters)\n",
    "print(loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda44c49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b46360",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01427d2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "28a5f8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(clusters.shape)\n",
    "print(old_clusters.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "fe00f049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False ... False False False]\n",
      "[False False False ...  True False False]\n",
      "[ True  True  True ... False  True False]\n",
      "[False False False ... False False False]\n",
      "[False False False ... False False  True]\n"
     ]
    }
   ],
   "source": [
    "cluster_data = []\n",
    "for val in range(k):\n",
    "    ind_cluster = clusters == val\n",
    "    print(ind_cluster)\n",
    "    cluster_data.append(df_test[ind_cluster])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "8bb446c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for i in range(k):\n",
    "    p, neu, neg = 0, 0, 0\n",
    "    for sentiment in cluster_data[i]['Sentiment']:\n",
    "        if sentiment == 'Positive': p += 1\n",
    "        if sentiment == 'Neutral': neu += 1\n",
    "        if sentiment == 'Negative': neg += 1\n",
    "    res.append([p, neu, neg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "e5611c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[460, 101, 191] 752\n",
      "[574, 356, 528] 1458\n",
      "[1855, 919, 1986] 4760\n",
      "[943, 357, 679] 1979\n",
      "[434, 213, 404] 1051\n"
     ]
    }
   ],
   "source": [
    "for r in res:\n",
    "    print(r, np.sum(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "7819f90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7486702127659575\n",
      "3.078875171467764\n",
      "3.01890756302521\n",
      "3.309247094492168\n",
      "3.1303520456707896\n"
     ]
    }
   ],
   "source": [
    "print(cluster_data[0]['Score'].mean())\n",
    "print(cluster_data[1]['Score'].mean())\n",
    "print(cluster_data[2]['Score'].mean())\n",
    "print(cluster_data[3]['Score'].mean())\n",
    "print(cluster_data[4]['Score'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "dc5c021b",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = np.array(list(df_test['Sentiment']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "fde9f1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = []\n",
    "for val in clusters:\n",
    "    if val==0 or val==1:\n",
    "        predicted.append('Negative')\n",
    "    if val==2:\n",
    "        predicted.append('Neutral')\n",
    "    if val==3 or val==4:\n",
    "        predicted.append('Positive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "8197c21e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(actual))\n",
    "print(len(list(df_test['Sentiment'])))\n",
    "print(len(predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "df2d66f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_1 = ['cluster_1', 'cluster_2', 'cluster_3', 'cluster_4', 'cluster_5']\n",
    "label_2 = ['Positive', 'Neutral', 'Negative']\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(np.array(res).transpose())\n",
    "plt.title('Confusion matrix of the classifier')\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + label_1)\n",
    "ax.set_yticklabels([''] + label_2)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8c1f65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e65dc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fe4c02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29008eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256b62d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48327c5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a885df4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a52af96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83606449",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fb68ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52a01e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dec7c07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a94498a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbde891",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82aa3cb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87871621",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5eaf76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379bd64c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90a93f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669911af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83daa1c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee08f0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b3c3ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c88c9fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41521d6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f5b146",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4d5e80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3115a87d",
   "metadata": {},
   "source": [
    "## Question 3 - Comparing classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07dbe82",
   "metadata": {},
   "source": [
    "### Dummy Classifier with strategy=\"most_frequent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dece65bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "whole_df = pd.read_csv('/home/sebastien/Documents/Glasgow/Semester2/Text_As_Data/coursework/archive/Reviews.csv')\n",
    "df = whole_df[:10000]\n",
    "#shuffled_reviews = random.sample(df, k=len(df))\n",
    "\n",
    "df.drop(['ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator', 'HelpfulnessDenominator', 'Time', 'Summary'], axis=1, inplace=True)\n",
    "df.loc[df['Score'] == 1, 'Sentiment'] = 'Negative'\n",
    "df.loc[df['Score'] == 2, 'Sentiment'] = 'Negative'\n",
    "df.loc[df['Score'] == 3, 'Sentiment'] = 'Neutral'\n",
    "df.loc[df['Score'] == 4, 'Sentiment'] = 'Positive'\n",
    "df.loc[df['Score'] == 5, 'Sentiment'] = 'Positive'\n",
    "\n",
    "train_frac = 0.6\n",
    "validation_frac= 0.8\n",
    "split_idx = int(train_frac * len(df))\n",
    "split_idxx = int(validation_frac * len(df))\n",
    "train_reviews = df[:split_idx]\n",
    "validation_reviews = df[split_idx:split_idxx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e52a5352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.77\n",
      "Precision: 0.26\n",
      "Recall: 0.33\n",
      "F1-score: 0.29\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_reviews.Text, train_reviews.Sentiment, test_size=0.25, random_state=42)\n",
    "\n",
    "# Instantiate the dummy classifier with strategy=\"most_frequent\"\n",
    "dummy = DummyClassifier(strategy=\"most_frequent\")\n",
    "\n",
    "# Train the classifier on the training data\n",
    "dummy.fit(X_train, y_train)\n",
    "\n",
    "# Use the classifier to predict the labels for the testing data\n",
    "y_pred = dummy.predict(X_test)\n",
    " \n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-score: {f1:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b538dc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c316bf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6eb95f44",
   "metadata": {},
   "source": [
    "### Dummy Classifier with strategy=\"stratified\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e8f14e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.62\n",
      "Precision: 0.34\n",
      "Recall: 0.34\n",
      "F1-score: 0.34\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_reviews.Text, train_reviews.Sentiment, test_size=0.25, random_state=42)\n",
    "\n",
    "# Instantiate the dummy classifier with strategy=\"stratified\"\n",
    "dummy = DummyClassifier(strategy=\"stratified\")\n",
    "\n",
    "# Train the classifier on the training data\n",
    "dummy.fit(X_train, y_train)\n",
    "\n",
    "# Use the classifier to predict the labels for the testing data\n",
    "y_pred = dummy.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-score: {f1:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3faba34a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e37bb99",
   "metadata": {},
   "source": [
    "### LogisticRegression with One-hot vectorization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2bca85f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[\"I've always wanted to like coconut water - low in calories, high in minerals - but I've just never liked the taste much. The pineapple juice in this really makes a difference. It still needs to be well chilled to be good, but it makes a healthy post-workout drink.\"\n 'I am giving this two stars as my family didnt mind the taste but the texture was so grainy and the biscuts fell apart easily. I was not a fan of the pancakes at all I believe they really didnt have a good flavor. Will not be wasting my money on such a tiny package either when you can but a bigger package of regular mix for less? Not fair to us with allergies in my opinion!!'\n \"These are so nice and creamy!  Usually I don't justify buying k-cups for things like cocoa that you can get cheaper in a packet, but this is so convenient and very good tasting .. way better than most powdered cocoa packets I've tried.  As far as price comparison, it is equivalent to gourmet-types of cocoa that would easily cost $1+ per packet.  I also like that it comes in a variety pack with 3 flavor options.  Highly recommend\"\n ...\n \"Enjoyed the product and they also provided very fast shipping.  I'm about out and need to order more.\"\n \"We love the Earth's Best line in our house. Our 9 mo old daughter  will ONLY eat Earth's Best dinners, and I don't blame her. The smell from both of the other 2 brand was nauseating. I've sampled the Earth's best dinners myself, and they aren't half bad... It is baby food.... The fruit blends and veggie blends are great as well.\"\n 'The chocolate on the stick was all melted and all the sticks were stuck with oneanother. The product and the concept is good but you will be better off buying it from a supermarket or directly get it from someone visiting Japan.'].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [75]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# One-hot encode the features\u001b[39;00m\n\u001b[1;32m      9\u001b[0m one_hot_encoder \u001b[38;5;241m=\u001b[39m OneHotEncoder(sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 10\u001b[0m X_train_one_hot \u001b[38;5;241m=\u001b[39m \u001b[43mone_hot_encoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m X_test_one_hot \u001b[38;5;241m=\u001b[39m one_hot_encoder\u001b[38;5;241m.\u001b[39mtransform(X_test)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Instantiate a LogisticRegression model\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:488\u001b[0m, in \u001b[0;36mOneHotEncoder.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;124;03mFit OneHotEncoder to X, then transform X.\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;124;03m    returned.\u001b[39;00m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_keywords()\n\u001b[0;32m--> 488\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/base.py:852\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    848\u001b[0m \u001b[38;5;66;03m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[1;32m    849\u001b[0m \u001b[38;5;66;03m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[1;32m    850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    851\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[0;32m--> 852\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m    853\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:461\u001b[0m, in \u001b[0;36mOneHotEncoder.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;124;03mFit OneHotEncoder to X.\u001b[39;00m\n\u001b[1;32m    445\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;124;03m    Fitted encoder.\u001b[39;00m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_keywords()\n\u001b[0;32m--> 461\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhandle_unknown\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_unknown\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_idx_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_drop_idx()\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:77\u001b[0m, in \u001b[0;36m_BaseEncoder._fit\u001b[0;34m(self, X, handle_unknown, force_all_finite)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_n_features(X, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_feature_names(X, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 77\u001b[0m X_list, n_samples, n_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_X\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_ \u001b[38;5;241m=\u001b[39m n_features\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategories \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:44\u001b[0m, in \u001b[0;36m_BaseEncoder._check_X\u001b[0;34m(self, X, force_all_finite)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03mPerform custom check_array:\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03m- convert list of strings to object dtype\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     40\u001b[0m \n\u001b[1;32m     41\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;66;03m# if not a dataframe, do normal check_array validation\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m     X_temp \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(X_temp\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39mstr_):\n\u001b[1;32m     46\u001b[0m         X \u001b[38;5;241m=\u001b[39m check_array(X, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mobject\u001b[39m, force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:769\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    767\u001b[0m     \u001b[38;5;66;03m# If input is 1D raise error\u001b[39;00m\n\u001b[1;32m    768\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 769\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    770\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    771\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    772\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    773\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m    774\u001b[0m         )\n\u001b[1;32m    776\u001b[0m \u001b[38;5;66;03m# make sure we actually converted to numeric:\u001b[39;00m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[\"I've always wanted to like coconut water - low in calories, high in minerals - but I've just never liked the taste much. The pineapple juice in this really makes a difference. It still needs to be well chilled to be good, but it makes a healthy post-workout drink.\"\n 'I am giving this two stars as my family didnt mind the taste but the texture was so grainy and the biscuts fell apart easily. I was not a fan of the pancakes at all I believe they really didnt have a good flavor. Will not be wasting my money on such a tiny package either when you can but a bigger package of regular mix for less? Not fair to us with allergies in my opinion!!'\n \"These are so nice and creamy!  Usually I don't justify buying k-cups for things like cocoa that you can get cheaper in a packet, but this is so convenient and very good tasting .. way better than most powdered cocoa packets I've tried.  As far as price comparison, it is equivalent to gourmet-types of cocoa that would easily cost $1+ per packet.  I also like that it comes in a variety pack with 3 flavor options.  Highly recommend\"\n ...\n \"Enjoyed the product and they also provided very fast shipping.  I'm about out and need to order more.\"\n \"We love the Earth's Best line in our house. Our 9 mo old daughter  will ONLY eat Earth's Best dinners, and I don't blame her. The smell from both of the other 2 brand was nauseating. I've sampled the Earth's best dinners myself, and they aren't half bad... It is baby food.... The fruit blends and veggie blends are great as well.\"\n 'The chocolate on the stick was all melted and all the sticks were stuck with oneanother. The product and the concept is good but you will be better off buying it from a supermarket or directly get it from someone visiting Japan.'].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_reviews.Text, train_reviews.Sentiment, test_size=0.25, random_state=42)\n",
    "\n",
    "# One-hot encode the features\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "X_train_one_hot = one_hot_encoder.fit_transform(X_train)\n",
    "X_test_one_hot = one_hot_encoder.transform(X_test)\n",
    "\n",
    "# Instantiate a LogisticRegression model\n",
    "logistic_reg = LogisticRegression(random_state=42)\n",
    "\n",
    "# Train the model on the one-hot encoded training data\n",
    "logistic_reg.fit(X_train_one_hot, y_train)\n",
    "\n",
    "# Use the trained model to predict the labels for the testing data\n",
    "y_pred = logistic_reg.predict(X_test_one_hot)\n",
    "\n",
    "# Evaluate the performance of the model using suitable metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af42860",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb999541",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e95c09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ac7ac4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "286047fe",
   "metadata": {},
   "source": [
    "### LogisticRegression with TF-IDF vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3432bf5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.82\n",
      "Precision: 0.66\n",
      "Recall: 0.45\n",
      "F1-score: 0.47\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_reviews.Text, train_reviews.Sentiment, test_size=0.25, random_state=42)\n",
    "\n",
    "# TF-IDF vectorize the text data\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Instantiate a LogisticRegression model\n",
    "logistic_reg = LogisticRegression(random_state=42)\n",
    "\n",
    "# Train the model on the TF-IDF vectorized training data\n",
    "logistic_reg.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Use the trained model to predict the labels for the testing data\n",
    "y_pred = logistic_reg.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the performance of the model using suitable metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-score: {f1:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f09a2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fae617",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d2a49f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcaa989",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72fbdf1b",
   "metadata": {},
   "source": [
    "### SVC Classifier with One-hot vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1f440ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.78\n",
      "Precision: 0.48\n",
      "Recall: 0.35\n",
      "F1-score: 0.33\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_reviews.Text, train_reviews.Sentiment, test_size=0.25, random_state=42)\n",
    "\n",
    "# One-hot vectorize the text data\n",
    "count_vectorizer = CountVectorizer()\n",
    "X_train_one_hot = count_vectorizer.fit_transform(X_train)\n",
    "X_test_one_hot = count_vectorizer.transform(X_test)\n",
    "\n",
    "# Instantiate an SVC classifier with RBF kernel and default settings\n",
    "svc = SVC(kernel='rbf')\n",
    "\n",
    "# Train the classifier on the one-hot vectorized training data\n",
    "svc.fit(X_train_one_hot, y_train)\n",
    "\n",
    "# Use the trained classifier to predict the labels for the testing data\n",
    "y_pred = svc.predict(X_test_one_hot)\n",
    "\n",
    "# Evaluate the performance of the classifier using suitable metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-score: {f1:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb73c83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a430afbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc0dc67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdef962",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37c41a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7ec47b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ededa8ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b146b7ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69db3e8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fdd2bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10401be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8219605",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ef5ac3d",
   "metadata": {},
   "source": [
    "## Q4 - Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50da6608",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff62e92f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b473702",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec2b738",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c909c2c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4741517b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e47d92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8358400",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647bcf4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe35d004",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f11475",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1912c39e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b9b464",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a530613c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3537bb1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac376535",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a4783edd",
   "metadata": {},
   "source": [
    "## Question 5 - Context vectors using BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "2204270b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, RobertaModel, RobertaTokenizer\n",
    "\n",
    "\n",
    "whole_df = pd.read_csv('archive/Reviews.csv')\n",
    "df = whole_df[:10000]\n",
    "df = df[[\"Text\", \"Score\"]]\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "model = RobertaModel.from_pretrained('roberta-base',  return_dict=True)\n",
    "\n",
    "def extract_first_context_vector(text):\n",
    "    input_ids = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    outputs = model(**input_ids)\n",
    "    return outputs[0]\n",
    "\n",
    "#inputs = tokenizer([\"Hello, my dog is cute\", \"My cat as well\"], padding=True, truncation=True, return_tensors=\"pt\")\n",
    "#outputs = model(**inputs)\n",
    "\n",
    "#last_hidden_states = outputs.last_hidden_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d167fcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = extract_first_context_vector(list(train_df[\"Text\"][0:10]))\n",
    "train_y = train_df[\"Score\"][0:10].values\n",
    "val_X = extract_first_context_vector(list(val_df[\"Text\"][0:10]))\n",
    "val_y = val_df[\"Score\"][0:10].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "46ec8a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 107, 768])\n",
      "(10,)\n",
      "torch.Size([10, 187, 768])\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape)\n",
    "print(train_y.shape)\n",
    "print(val_X.shape)\n",
    "print(val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "1d0f213b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = torch.tensor(train_y)\n",
    "val_y = torch.tensor(val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "86e3e5a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 107, 768])\n",
      "torch.Size([10])\n",
      "torch.Size([10, 187, 768])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape)\n",
    "print(train_y.shape)\n",
    "print(val_X.shape)\n",
    "print(val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "bba22290",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = train_X.shape[0]\n",
    "train_X_2d = train_X.view(n_samples, -1)\n",
    "\n",
    "samp = val_X.shape[0]\n",
    "val_X_2d = val_X.view(samp, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "1fe56403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 82176])\n",
      "torch.Size([10, 143616])\n"
     ]
    }
   ],
   "source": [
    "print(train_X_2d.shape)\n",
    "print(val_X_2d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "5e4a6361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000, random_state=42)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=42, max_iter=1000)\n",
    "clf.fit(torch.tensor(train_X_2d), torch.tensor(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd41da5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "3c6ac24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 143616])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "print(val_X_2d.shape)\n",
    "print(val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "312596e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = train_X.shape[1]\n",
    "val_X_padded = []\n",
    "for seq in val_X:\n",
    "    if seq.shape[0] > max_len:\n",
    "        seq = seq[:max_len]\n",
    "    diff = max_len - seq.shape[0]\n",
    "    seq_padded = torch.cat([seq, torch.zeros(diff, seq.shape[1])], dim=0)\n",
    "    val_X_padded.append(seq_padded)\n",
    "val_X_padded = torch.stack(val_X_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "6033363e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 107, 768])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_X_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "f0d14cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train_samples = train_X.shape[0]\n",
    "n_val_samples = val_X_padded.shape[0]\n",
    "train_X_2d = train_X.view(n_train_samples, -1)\n",
    "val_X_2d = val_X_padded.view(n_val_samples, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "33d2008a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 82176])\n",
      "torch.Size([10, 82176])\n"
     ]
    }
   ],
   "source": [
    "print(train_X_2d.shape)\n",
    "print(val_X_2d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "60aab7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_X_2d = torch.tensor(val_X_2d)\n",
    "val_y = torch.tensor(val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "bef47ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3\n",
      "F1 score: 0.11538461538461538\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(val_X_2d)\n",
    "accuracy = accuracy_score(val_y, pred)\n",
    "f1 = f1_score(val_y, pred, average=\"macro\")\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a334cf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66e25e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069b63af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a78ba1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb953db5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e41b86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8a017e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cda7ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0efdcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb5531d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3128818",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb16539",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a29c0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621ff4d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a55408",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f09588",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33f0af5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e445c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f0fbe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c7ae2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c175bb44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5f703d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effbf0a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514d3c58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
